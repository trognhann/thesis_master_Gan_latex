\documentclass[a4paper,12pt,oneside]{book}%extreport
\usepackage{times} 
% \usepackage{multibib}
\usepackage{lipsum}
\usepackage{appendix}
\usepackage[shortlabels]{enumitem}
\usepackage{booktabs}
\usepackage{rotating} % Rotating table
\usepackage{hhline}
\usepackage{colortbl}
\usepackage{makecell}
\usepackage{afterpage}
\usepackage{mathtools} %Fixes/improves amsmath
\usepackage{setspace}
\usepackage[utf8]{vietnam} 
\usepackage{amstext, amsmath,latexsym,amsbsy,amssymb, amssymb,amsthm,amsfonts,multicol, nccmath}
\usepackage[left=3cm,right=2cm,top=2.5cm,bottom=3cm,footskip=40pt]{geometry}
\usepackage{pdflscape}
\usepackage{apacite}
\usepackage{tikz}
\usepackage{array}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{subfig}
\usetikzlibrary{calc}
\usepackage{tabularx}
\usepackage{multicol}
\usepackage{array,color,colortbl}
\setcounter{secnumdepth}{4}
 %\usepackage[square,numbers]{natbib}
\usepackage[square, comma, numbers, sort&compress]{natbib}
\setlength{\parindent}{1cm}
\usepackage{color}
\usepackage{indentfirst}
\usepackage{exscale,eucal}
\usepackage{fancyhdr}
\usepackage{fncychap}
\usepackage[chapter]{algorithm}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{algpseudocode}
\usepackage{tabularx,multicol,multirow,longtable}
\usepackage{etoolbox}
\usepackage{tikz}	\usetikzlibrary{calc,arrows,decorations.pathmorphing,backgrounds,positioning,fit,shapes,decorations.shapes, shapes.geometric, decorations.pathreplacing, decorations.text}
 
	\tikzstyle{block} = [draw,rectangle,thick,minimum height=2em,minimum width=2em,drop shadow,fill=blue!50]
	\tikzstyle{sum} = [draw,circle,inner sep=0mm,minimum size=2mm]
	\tikzstyle{connector} = [->,thick]
	\tikzstyle{line} = [very thick]
	\tikzstyle{branch} = [circle,inner sep=0pt,minimum size=1mm,fill=black,draw=black]
	\tikzstyle{axes} = [->,>=stealth',semithick]
	\tikzstyle{important line} = [very thick,draw=red]
	\tikzstyle{important text} = [rounded corners,fill=red!10,inner sep=1ex]
\usepackage{circuitikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage[numbers]{natbib}
\usepackage{titlesec}
\usepackage[labelsep=period]{caption}
% \usepackage{subfigure}
\usepackage{caption}
\usepackage{subcaption}

\DeclareCaptionFormat{myformat}{\fontsize{13}{15}\selectfont#1#2#3}
\captionsetup{format=myformat}
\usepackage{titletoc}
\titlelabel{\thetitle.\,\,}
\titleformat{\chapter}[display] 
  {\fontsize{14}{16}\selectfont\bfseries\centering}
  {\MakeUppercase{\chaptertitlename}\ \thechapter}{0pt}{\fontsize{14}{16}\selectfont\MakeUppercase}
\titlespacing{\chapter}{0pt}{0pt}{40pt} 
\titleformat*{\section}{\fontsize{14}{14}\selectfont\bfseries}
\titleformat*{\subsection}{\fontsize{14}{14}\selectfont\bfseries\slshape}
\titleformat*{\subsubsection}{\fontsize{14}{14}\slshape}
\titleformat*{\paragraph}{\large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}
\graphicspath {{figures/}}

\titlespacing\section{0pt}{6pt plus 4pt minus 2pt}{1pt plus 2pt minus 2pt} 
\titlespacing\subsection{0pt}{6pt plus 4pt minus 2pt}{1pt plus 2pt minus 2pt}
\titlespacing\subsubsection{0pt}{6pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}
\titlespacing\subsubsubsection{0pt}{6pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}

\usepackage[subfigure]{tocloft} 

\cftsetpnumwidth{20pt}
\titlecontents{chapter}
  [0pt]
  {}
  {\fontsize{13.5}{14}\selectfont\MakeUppercase{\chaptername}\ \thecontentslabel.\,\,}
  {}
  {\cftdotfill{\cftdotsep}\contentspage} 
	\renewcommand{\cftsecaftersnum}{.}%
	\renewcommand{\cftsubsecaftersnum}{.}%

\usetikzlibrary{calc}
\newtheorem{definition}{\bf Định nghĩa}[chapter]
\newtheorem{theorem}{\bf Định lý}[chapter]
\newtheorem{lemma}{\bf Bổ đề}[chapter]

\renewcommand{\cftfigfont}{Hình~}
\renewcommand{\cfttabfont}{Bảng~ }
\usepackage{float}
\floatname{algorithm}{Thuật toán}
\makeatletter
\renewcommand\@biblabel[1]{[#1]}
\renewcommand\harvardyearleft{\unskip~(}
\renewcommand\harvardyearright{\unskip )}
\makeatother
\renewcommand{\baselinestretch}{1.4}
\flushbottom
\renewcommand*{\bibfont}{\fontsize{13}{16}\selectfont}

\usepackage[hidelinks, unicode]{hyperref}

\begin{document}
\fontsize{13}{15.5}\selectfont

\pagestyle{empty}
\input{cover/cover}
\newpage

\def\baselinestretch{1.3}
\pagestyle{plain}
\pagenumbering{gobble}
\input{cover/acknowledgement.tex}
\newpage
\input{cover/assurance.tex} 
\newpage
\input{cover/abstract_vn.tex}
\newpage
\input{cover/abstract_en.tex}
\newpage
\pagenumbering{roman}


\setlength{\parindent}{1cm}
\setlength{\parskip}{0.6ex}

\fontsize{13}{16}\selectfont
\renewcommand{\contentsname}{\vspace{-70pt}\centerline{\fontsize{14}{16}\selectfont\MakeUppercase{Mục lục}}}
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Mục lục}
\tableofcontents
\clearpage
% \input{cover/tomtat}
\newpage
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Danh mục hình vẽ}
\renewcommand{\listfigurename}{\vspace{-70pt}\centerline{\fontsize{14}{16}\selectfont{\MakeUppercase{Danh mục   hình vẽ}}}}
\listoffigures
\fontsize{13}{16}\selectfont
\newpage
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{Danh mục bảng biểu}
\renewcommand{\listtablename}{\vspace{-70pt}\centerline{\fontsize{14}{16}\selectfont{\MakeUppercase{Danh mục bảng biểu}}}}
\listoftables
\fontsize{13}{16}\selectfont
\newpage

\clearpage
\input{cover/symbol.tex}
\newpage

\pagenumbering{arabic}
\pagestyle{plain}

\input{chapter/chap0_intro.tex}
\newpage
\input{chapter/chap1_Prologue.tex}
\newpage
% \input{chapter/Chap2_thietke_mophong}
% \newpage
% \input{chapter/Chap3_Main}
% \newpage
% \input{chapter/Chap4_Ketluan}
% \newpage

\appendix
% \input{cover/phuluc}
\def\baselinestretch{1}
\vspace{-2cm}
\renewcommand{\bibname}{Tài liệu tham khảo}
\clearpage
\phantomsection
\addcontentsline{toc}{chapter}{{TÀI LIỆU THAM KHẢO}}
\renewcommand{\refname}{Literary works}
\begin{thebibliography}{xx}
	\section*{Tiếng Anh}
	\vspace{0.3cm}

\harvarditem{{Al-Waisy et al.}}{2019}{AlWaisy2019}
Al-Waisy, A. S., et al. (2019), ``Multi-Scale Inception Based Super-Resolution Using Deep Learning Approach'', {\em Electronics}, Vol. 8(8), pp. 892.

\harvarditem{{Arnaud58}}{n.d.}{Selfie2Anime}
Arnaud58 (n.d.), ``selfie2anime - Kaggle'', {\em https://www.kaggle.com/datasets/arnaud58/selfie2anime}.

\harvarditem{{Ashraf et al.}}{2023}{Ashraf2023}
Ashraf, S. M. N., Mamun, M. A., Abdullah, H. M., Alam, M. G. R. (2023), ``SynthEnsemble: A Fusion of CNN, Vision Transformer, and Hybrid Models for Multi-Label Chest X-Ray Classification'', {\em 2023 International Conference on Computer and Information Technology (ICCIT)}, arXiv:2311.07750.

\harvarditem{{Basha et al.}}{2020}{Basha2020}
Basha, S. H. S., Dubey, S. R., Pulabaigari, V., Mukherjee, S. (2020), ``Impact of Fully Connected Layers on Performance of Convolutional Neural Networks for Image Classification'', {\em Neurocomputing}, Vol. 378, pp. 178-189.

\harvarditem{{Chen et al.}}{2020}{Chen2020}
Chen, J., Liu, G., Chen, X. (2020), ``AnimeGAN: A Novel Lightweight GAN for Photo Animation'', {\em Artificial Intelligence Algorithms and Applications}, Springer, Singapore, pp. 242-256.

\harvarditem{{Chen \& Liu}}{2020}{ChenLiu2020}
Chen, X., Liu, G. (2020), ``AnimeGANv2'', {\em https://tachibanayoshino.github.io/AnimeGANv2/}.

\harvarditem{{Gholamalinezhad \& Khosravi}}{2022}{Gholamalinezhad2022}
Gholamalinezhad, H., Khosravi, H. (2022), ``A Comparison of Pooling Methods for Convolutional Neural Networks'', {\em Applied Sciences}, Vol. 12(17), pp. 8643.

\harvarditem{{Girshick et al.}}{2014}{Girshick2014}
Girshick, R., Donahue, J., Darrell, T., Malik, J. (2014), ``Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation'', {\em Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}.

\harvarditem{{He et al.}}{2017}{He2017}
He, K., Gkioxari, G., Dollár, P., Girshick, R. (2017), ``Mask R-CNN'', {\em arXiv preprint arXiv:1703.06870}.

\harvarditem{{Hippocampus's Garden}}{2021}{Hippocampus2021}
Hippocampus's Garden (2021), ``Awesome StyleGAN Applications'', {\em https://hippocampus-garden.com/stylegans/}.

\harvarditem{{Hussain et al.}}{2018}{Hussain2018}
Hussain, M., Bird, J. J., Faria, D. R. (2018), ``A Study on CNN Transfer Learning for Image Classification'', {\em Advances in Intelligent Systems and Computing}, Vol. 840, Springer, pp. 191–202.

\harvarditem{{Lin}}{2025}{Lin2025}
Lin, F. (2025), ``Vision Language Models: A Survey of 26K Papers'', {\em arXiv preprint arXiv:2510.09586}.

\harvarditem{{Liu et al.}}{2024}{Liu2024}
Liu, G., Chen, X., Gao, Z. (2024), ``A Novel Double-Tail Generative Adversarial Network for Fast Photo Animation'', {\em IEICE Transactions on Information and Systems}, Vol. E107.D(1), pp. 72-82.

\harvarditem{{Liu et al.}}{2024}{AnimeGANv3}
Liu, G., Chen, X., Gao, Z. (2024), ``AnimeGANv3: A Novel Double-Tail Generative Adversarial Network for Fast Photo Animation'', {\em https://tachibanayoshino.github.io/AnimeGANv3/}.

\harvarditem{{Liu et al.}}{2017}{Liu2017}
Liu, M.-Y., Breuel, T., Kautz, J. (2017), ``Unsupervised Image-to-Image Translation Networks'', {\em Advances in Neural Information Processing Systems (NIPS)}.

\harvarditem{{Lo et al.}}{2024}{Lo2024}
Lo, S.-L., Cheng, H.-Y., Yu, C.-C. (2024), ``Feature Weighted Cycle Generative Adversarial Network with Facial Landmark Recognition and Perceptual Color Distance for Enhanced Face Animation Generation'', {\em Electronics}, Vol. 13(23), pp. 4761.

\harvarditem{{Lu et al.}}{2024}{Lu2024}
Lu, Z., Zhou, Y., Chen, A. (2024), ``Enhancing Photo Animation: Augmented Stylistic Modules and Prior Knowledge Integration'', {\em Proceedings of the Asian Conference on Computer Vision (ACCV)}, pp. 1470–1485.

\harvarditem{{Radford et al.}}{2015}{Radford2015}
Radford, A., Metz, L., Chintala, S. (2015), ``Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks'', {\em arXiv preprint arXiv:1511.06951}.

\harvarditem{{Saad et al.}}{2024}{Saad2024}
Saad, M. M., O'Reilly, R., Rehmani, M. H. (2024), ``A survey on training challenges in generative adversarial networks for biomedical image analysis'', {\em Artificial Intelligence Review}, Vol. 57(2).

\harvarditem{{Stanford University}}{n.d.}{CS231n}
Stanford University (n.d.), ``CS231n: Deep Learning for Computer Vision'', {\em http://vision.stanford.edu/teaching/cs231n/}.

\harvarditem{{Szegedy et al.}}{2017}{Szegedy2017}
Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A. A. (2017), ``Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning'', {\em Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence}, pp. 4278-4284.

\harvarditem{{Unknown}}{2025}{ViTvsCNN2025}
Unknown (2025), ``A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation'', {\em arXiv preprint arXiv:2510.04794}.

\harvarditem{{Wang et al.}}{n.d.}{WangLAST}
Wang, Y., Wen, R., Ishii, H., Ohya, J. (n.d.), ``LAST: Utilizing Synthetic Image Style Transfer to Tackle Domain Shift in Aerial Image Segmentation'', {\em SciTePress}.

\harvarditem{{Wikipedia}}{n.d.}{WikiAlexNet}
Wikipedia (n.d.), ``AlexNet'', {\em https://en.wikipedia.org/wiki/AlexNet}.

\harvarditem{{Wikipedia}}{n.d.}{WikiCNN}
Wikipedia (n.d.), ``Convolutional neural network'', {\em https://en.wikipedia.org/wiki/Convolutional\_neural\_network}.

\harvarditem{{Yang et al.}}{2022}{Yang2022}
Yang, S., Jiang, L., Liu, Z., Loy, C. C. (2022), ``Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer'', {\em Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, pp. 11728-11737.

\harvarditem{{Zhang \& Tang}}{2025}{Zhang2025}
Zhang, T., Tang, H. (2025), ``Style Transfer: A Decade Survey'', {\em arXiv preprint arXiv:2506.19278}.

\harvarditem{{Zhou et al.}}{2018}{Zhou2018}
Zhou, Z., Siddiquee, M. R., Tajbakhsh, N., Liang, J. (2018), ``UNet++: A Nested U-Net Architecture for Medical Image Segmentation'', {\em Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support}, Vol. 11045, Springer, Cham, pp. 3-11.

\harvarditem{{Zhu et al.}}{2017}{Zhu2017}
Zhu, J.-Y., Park, T., Isola, P., Efros, A. A. (2017), ``Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks'', {\em Proceedings of the IEEE International Conference on Computer Vision (ICCV)}.

\end{thebibliography}

\end{document}
